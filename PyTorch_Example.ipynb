{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PyTorch_Example.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ruWJ4cTz794Z"},"source":["# Training a Neural Network with PyTorch"]},{"cell_type":"code","metadata":{"id":"E4yVVSMZ7YGi"},"source":["import torch\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D43h2egN8qm9"},"source":["## Load data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"8pm7sprm8Tvb","executionInfo":{"status":"ok","timestamp":1638914325855,"user_tz":-120,"elapsed":8,"user":{"displayName":"Pavlos Apostolatos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUcIhXd9Iu-oLhTPKlwqLJcWeuJzkMcL0JT3cW=s64","userId":"18149797479608505262"}},"outputId":"9d4cd6fb-bc44-44a9-a409-a263faa93f6a"},"source":["data = pd.read_csv('/content/sample_data/california_housing_train.csv')\n","data.describe()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>longitude</th>\n","      <th>latitude</th>\n","      <th>housing_median_age</th>\n","      <th>total_rooms</th>\n","      <th>total_bedrooms</th>\n","      <th>population</th>\n","      <th>households</th>\n","      <th>median_income</th>\n","      <th>median_house_value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>17000.000000</td>\n","      <td>17000.000000</td>\n","      <td>17000.000000</td>\n","      <td>17000.000000</td>\n","      <td>17000.000000</td>\n","      <td>17000.000000</td>\n","      <td>17000.000000</td>\n","      <td>17000.000000</td>\n","      <td>17000.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>-119.562108</td>\n","      <td>35.625225</td>\n","      <td>28.589353</td>\n","      <td>2643.664412</td>\n","      <td>539.410824</td>\n","      <td>1429.573941</td>\n","      <td>501.221941</td>\n","      <td>3.883578</td>\n","      <td>207300.912353</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>2.005166</td>\n","      <td>2.137340</td>\n","      <td>12.586937</td>\n","      <td>2179.947071</td>\n","      <td>421.499452</td>\n","      <td>1147.852959</td>\n","      <td>384.520841</td>\n","      <td>1.908157</td>\n","      <td>115983.764387</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>-124.350000</td>\n","      <td>32.540000</td>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>1.000000</td>\n","      <td>0.499900</td>\n","      <td>14999.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>-121.790000</td>\n","      <td>33.930000</td>\n","      <td>18.000000</td>\n","      <td>1462.000000</td>\n","      <td>297.000000</td>\n","      <td>790.000000</td>\n","      <td>282.000000</td>\n","      <td>2.566375</td>\n","      <td>119400.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>-118.490000</td>\n","      <td>34.250000</td>\n","      <td>29.000000</td>\n","      <td>2127.000000</td>\n","      <td>434.000000</td>\n","      <td>1167.000000</td>\n","      <td>409.000000</td>\n","      <td>3.544600</td>\n","      <td>180400.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>-118.000000</td>\n","      <td>37.720000</td>\n","      <td>37.000000</td>\n","      <td>3151.250000</td>\n","      <td>648.250000</td>\n","      <td>1721.000000</td>\n","      <td>605.250000</td>\n","      <td>4.767000</td>\n","      <td>265000.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>-114.310000</td>\n","      <td>41.950000</td>\n","      <td>52.000000</td>\n","      <td>37937.000000</td>\n","      <td>6445.000000</td>\n","      <td>35682.000000</td>\n","      <td>6082.000000</td>\n","      <td>15.000100</td>\n","      <td>500001.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          longitude      latitude  ...  median_income  median_house_value\n","count  17000.000000  17000.000000  ...   17000.000000        17000.000000\n","mean    -119.562108     35.625225  ...       3.883578       207300.912353\n","std        2.005166      2.137340  ...       1.908157       115983.764387\n","min     -124.350000     32.540000  ...       0.499900        14999.000000\n","25%     -121.790000     33.930000  ...       2.566375       119400.000000\n","50%     -118.490000     34.250000  ...       3.544600       180400.000000\n","75%     -118.000000     37.720000  ...       4.767000       265000.000000\n","max     -114.310000     41.950000  ...      15.000100       500001.000000\n","\n","[8 rows x 9 columns]"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2EIP1OaJOFak","executionInfo":{"status":"ok","timestamp":1638914326262,"user_tz":-120,"elapsed":2,"user":{"displayName":"Pavlos Apostolatos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUcIhXd9Iu-oLhTPKlwqLJcWeuJzkMcL0JT3cW=s64","userId":"18149797479608505262"}},"outputId":"5b0f09ae-553b-4f3a-f603-0dd55a63dfb9"},"source":["#Fill NaN values\n","data = data.fillna(0)\n","#Normalize values\n","data = (data-data.mean())/data.std()\n","#Separate features and targets\n","x_df = pd.DataFrame(data, columns=data.columns[:-1])\n","y_df = pd.DataFrame(data, columns=[data.columns[-1]])\n","print(x_df)\n","print(y_df)\n","\n","#Save in tensors\n","x = torch.tensor(x_df.values, dtype=torch.float)\n","y = torch.tensor(y_df.values, dtype=torch.float)\n","\n","print(f\"x shape: {x.shape}\")\n","print(f\"y shape: {y.shape}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["       longitude  latitude  ...  households  median_income\n","0       2.619288 -0.671500  ...   -0.075996      -1.252506\n","1       2.539494 -0.573248  ...   -0.099401      -1.081451\n","2       2.494610 -0.905436  ...   -0.999223      -1.170071\n","3       2.489623 -0.928830  ...   -0.715753      -0.362590\n","4       2.489623 -0.961581  ...   -0.622130      -1.026424\n","...          ...       ...  ...         ...            ...\n","16995  -2.342894  2.318197  ...   -0.343862      -0.799975\n","16996  -2.347881  2.369663  ...   -0.094200      -0.715705\n","16997  -2.362842  2.907715  ...   -0.117606      -0.446650\n","16998  -2.362842  2.889000  ...   -0.060392      -0.997758\n","16999  -2.387778  2.299482  ...   -0.601325      -0.455349\n","\n","[17000 rows x 8 columns]\n","       median_house_value\n","0               -1.210522\n","1               -1.096713\n","2               -1.048430\n","3               -1.154480\n","4               -1.222593\n","...                   ...\n","16995           -0.826848\n","16996           -1.106197\n","16997           -0.894099\n","16998           -1.047568\n","16999           -0.971696\n","\n","[17000 rows x 1 columns]\n","x shape: torch.Size([17000, 8])\n","y shape: torch.Size([17000, 1])\n"]}]},{"cell_type":"markdown","metadata":{"id":"i10vl9KnOwfE"},"source":["## Create a Neural Network"]},{"cell_type":"code","metadata":{"id":"wTlyzUiG8p5V"},"source":["class Net(nn.Module):\n","    def __init__(self, D_in, H1, H2, H3, D_out):\n","        super(Net, self).__init__()\n","        self.linear1 = nn.Linear(D_in, H1)\n","        self.linear2 = nn.Linear(H1, H2)\n","        self.linear3 = nn.Linear(H2, H3)\n","        self.linear4 = nn.Linear(H3, D_out)\n","        \n","    def forward(self, x):\n","        h1 = self.linear1(x)\n","        h2 = self.linear2(h1)\n","        h3 = self.linear3(h2)\n","        out = self.linear4(h3)\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BXAcc2dLPPUe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638904820327,"user_tz":-120,"elapsed":253,"user":{"displayName":"Pavlos Apostolatos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUcIhXd9Iu-oLhTPKlwqLJcWeuJzkMcL0JT3cW=s64","userId":"18149797479608505262"}},"outputId":"163dfd5a-5398-4c79-f33d-e61bd92c72da"},"source":["#Define layer sizes\n","D_in = x.shape[1]\n","print(D_in)\n","H1 = 128\n","H2 = 64\n","H3 = 32\n","D_out = 1\n","\n","#Define Hyperparameters\n","learning_rate = 1e-4\n","\n","#Initialize model, loss, optimizer\n","model = Net(D_in, H1, H2, H3, D_out)\n","loss_func = nn.MSELoss(reduction='sum')\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","\n","#Initialize dataloader\n","dataset = torch.utils.data.TensorDataset(x, y)\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)\n","for data in dataloader:\n","  print (data)\n","  break"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["8\n","[tensor([[ 0.7441, -0.8119,  0.0326, -0.6907, -0.7649, -0.4056, -0.7262,  0.3424],\n","        [ 0.6045, -0.7510,  0.4299,  1.1809,  2.4593,  1.8368,  2.2620, -1.2417],\n","        [-0.8617,  1.1111, -1.9536, -0.5742, -0.5158,  0.3088, -0.4999, -0.7906],\n","        [ 0.6344, -0.7230,  0.7477, -1.0384, -0.9713, -0.8578, -0.9394, -1.0245],\n","        [ 0.6394, -0.7464,  1.3038, -0.7801, -0.5941, -0.4152, -0.6845, -0.9518],\n","        [ 1.1281, -0.6809,  0.1121, -0.0737,  0.0797, -0.2244, -0.1644, -1.0526],\n","        [-1.7544,  1.2889, -0.0468,  0.2997,  0.3241, -0.4413, -0.3335,  0.0174],\n","        [ 0.8040, -0.8820, -1.0002,  0.0570,  0.1437, -0.2157,  0.1607, -0.0877],\n","        [ 0.7890, -0.8820,  0.0326,  0.3667,  0.2268,  0.7208,  0.3089,  0.4490],\n","        [-1.1360,  0.7649, -1.8741, -0.3833, -0.4731, -0.5267, -0.4219,  0.6118],\n","        [-1.2856,  0.9707, -0.9207, -0.5416, -0.5870, -0.6400, -0.4453,  0.3681],\n","        [ 0.7491, -0.8353, -0.6824,  1.3759,  1.6408,  2.1008,  1.8043,  0.0894],\n","        [-1.3205,  1.0175,  0.8271, -0.2870, -0.2192, -0.1817, -0.1436, -0.4234],\n","        [ 0.6943, -0.7370,  1.3038, -0.8765, -0.8574, -0.6225, -0.8744, -0.6747],\n","        [ 0.8389, -0.8774,  1.7010, -0.5962, -0.7388, -0.5947, -0.6949,  0.3296],\n","        [-1.1510,  0.8117,  0.4299, -0.7824, -0.7056, -0.5755, -0.7158, -0.1683],\n","        [ 1.2079, -1.3686,  1.2243, -0.9109, -0.7625, -0.4884, -0.7522, -1.0218],\n","        [ 1.1132, -0.7370, -0.2057, -0.9315, -0.9262, -0.8699, -0.9654, -1.3028],\n","        [-1.4751,  1.0877,  0.3504,  0.8277,  0.2173,  0.2138,  0.3297,  2.0998],\n","        [-1.5998,  1.2655,  0.2710, -0.2705, -0.5111, -0.5110, -0.5077,  0.3689],\n","        [ 0.7242, -0.7931, -0.9207, -0.6600, -0.4565, -0.6042, -0.4141, -0.3577],\n","        [ 0.1756, -0.6294, -0.1263, -0.1948, -0.5395, -0.4291, -0.4843,  0.9834],\n","        [ 0.7741, -0.7791,  0.5888, -0.3847, -0.5965, -0.4770, -0.5025,  0.7451],\n","        [ 1.5570, -0.8820, -1.8741, -0.8246, -0.6890, -1.1435, -1.1293,  2.1513],\n","        [ 0.6195, -0.8867, -0.2852, -0.7086, -0.8812, -0.8909, -0.8900,  1.9941],\n","        [-1.2906,  0.8070, -0.4441,  0.5369, -0.1291, -0.0746, -0.0968,  4.7667],\n","        [-1.1260,  0.7649, -1.4769,  0.1772,  0.0821,  0.1685,  0.2283,  0.6561],\n","        [-0.7470,  1.0456, -0.3646, -0.4269, -0.5016, -0.1495, -0.4609, -0.6292],\n","        [-0.8717,  1.4246, -0.2057, -0.5765, -0.7436, -0.5424, -0.6689,  0.1429],\n","        [ 0.5446, -0.7604, -0.0468, -0.6352, -0.5633, -0.6635, -0.5753,  0.2084],\n","        [ 0.6045, -0.7698,  1.4627, -0.0604, -0.1860, -0.3028, -0.1956, -0.0315],\n","        [-1.4253,  1.0035,  1.8599, -0.7145, -0.4517, -0.7323, -0.3647, -0.7153],\n","        [-0.0937, -0.5592, -0.4441,  0.1552,  0.7060, -0.0981,  0.7432, -0.2652],\n","        [ 1.1680, -1.1394, -1.0002,  0.1653,  0.2766,  0.4516,  0.2725, -0.6193],\n","        [ 0.7242, -0.8212,  0.3504, -0.5801, -0.6771, -0.5528, -0.5311,  0.4128],\n","        [ 0.9486, -0.9475, -0.2852,  0.5052, -0.0413,  0.1903, -0.0136,  1.9208],\n","        [-0.8817,  1.4012, -0.7618, -0.3627, -0.2952, -0.5729, -0.2710, -0.8522],\n","        [ 0.5646, -0.7510,  0.7477, -0.2164, -0.2430, -0.5223, -0.3465,  0.0134],\n","        [ 1.0134, -0.9054, -1.7947, -1.0045, -1.0377, -1.0599, -1.1917,  3.7140],\n","        [ 0.6145, -0.7089,  0.7477,  0.3905,  1.3300,  0.4438,  1.2815, -0.8745],\n","        [-0.8667,  1.4292, -0.7618,  0.0052, -0.2406, -0.1538, -0.1228,  0.7327],\n","        [-1.6247,  1.3170, -0.4441, -0.5012, -0.7198, -0.7619, -0.6715,  0.4170],\n","        [ 0.3053, -0.3721, -0.8413,  0.2910,  0.5281, -0.0798,  0.1269, -0.4688],\n","        [-1.3405,  1.1626,  1.8599,  0.0928,  0.3929,  0.0779,  0.3089, -0.8836],\n","        [ 0.6444, -0.7043,  1.7010, -0.2783, -0.2359, -0.2967, -0.2190, -0.1617],\n","        [ 0.6843, -0.7651,  0.7477, -0.6567, -0.6344, -0.2619, -0.6195, -0.6374],\n","        [ 0.6045, -0.7651,  1.3038, -0.4035, -0.3284, -0.6539, -0.4349, -0.3571],\n","        [ 0.7940, -0.8680, -0.5235, -0.1833,  0.0844,  0.0988,  0.0826, -0.6403],\n","        [ 0.9735, -0.6996, -0.6030,  2.6479,  2.0085,  2.5077,  2.1840,  0.3027],\n","        [-1.4602,  1.0082,  1.8599,  0.3653,  0.4332,  0.2034,  0.4259, -0.4485],\n","        [-1.1510,  1.9252, -1.7152, -0.4159, -0.5917, -0.5947, -0.6143,  0.0086],\n","        [ 1.2528, -1.3359, -0.4441, -0.0402,  0.2908, -0.2000,  0.1217, -1.0448],\n","        [ 0.6843, -0.7698,  0.5888,  0.7043,  1.7238,  2.7464,  1.8069, -0.9826],\n","        [-0.3830,  1.0971, -0.9207, -0.0521, -0.0318, -0.3533, -0.0136, -0.9841],\n","        [-1.2856,  1.0549,  0.4299,  1.9919,  1.3205,  1.2505,  1.6196,  1.2284],\n","        [-0.4628,  0.7883,  1.3038, -0.3714, -0.2809, -0.0214, -0.2450, -0.9598],\n","        [-1.3205,  1.0316,  0.4299,  1.1107,  0.5898,  0.1720,  0.6886,  1.5795],\n","        [ 1.2578, -1.4061, -0.1263, -0.4283, -0.6107, -0.2967, -0.5311,  0.4170],\n","        [-0.8418,  1.4854, -1.1591,  1.1240,  0.4498,  0.4743,  0.5300,  0.8579],\n","        [-0.9415,  1.3403,  0.4299,  0.4263,  0.2908,  0.0962,  0.3089, -0.1841],\n","        [-1.3056,  1.0035, -0.1263, -0.7957, -0.7198, -0.9004, -0.8952, -0.9459],\n","        [ 0.9885, -0.8212, -0.9207,  0.0589, -0.2145,  0.2225, -0.1046,  0.6094],\n","        [ 0.6145, -0.7978, -0.4441, -0.7682, -0.5965, -0.6617, -0.6507, -0.3231],\n","        [ 0.7242, -0.7604, -0.3646, -0.1104,  0.1200,  0.5867,  0.1191, -0.6050]]), tensor([[-1.8969e-01],\n","        [-7.6305e-01],\n","        [-7.1390e-01],\n","        [-6.0182e-01],\n","        [-4.8025e-01],\n","        [-1.0139e+00],\n","        [ 2.1813e-01],\n","        [-5.2601e-02],\n","        [ 1.7165e-03],\n","        [-1.9400e-01],\n","        [-1.7331e-01],\n","        [-3.3540e-01],\n","        [-4.8542e-01],\n","        [-7.1735e-01],\n","        [-1.0261e-01],\n","        [-1.1037e-01],\n","        [-1.0165e+00],\n","        [-1.1571e+00],\n","        [ 2.2546e+00],\n","        [ 7.1906e-01],\n","        [-3.8627e-01],\n","        [ 6.3629e-01],\n","        [ 5.7076e-01],\n","        [ 1.6899e+00],\n","        [ 2.5236e+00],\n","        [ 2.5236e+00],\n","        [ 9.8282e-02],\n","        [-3.2678e-01],\n","        [-6.1734e-01],\n","        [ 1.5269e+00],\n","        [ 2.5787e-03],\n","        [ 3.6815e-01],\n","        [ 6.5439e-01],\n","        [ 8.2762e-02],\n","        [ 2.1123e-01],\n","        [ 6.1042e-01],\n","        [-6.1647e-01],\n","        [ 2.5236e+00],\n","        [ 2.3796e+00],\n","        [ 1.9917e+00],\n","        [-5.7509e-01],\n","        [ 8.3976e-01],\n","        [-7.8288e-01],\n","        [-9.4324e-01],\n","        [ 2.0088e-01],\n","        [-5.6043e-01],\n","        [ 1.2760e-01],\n","        [-2.3883e-01],\n","        [-3.6816e-01],\n","        [ 1.2847e+00],\n","        [-5.1991e-01],\n","        [-5.1387e-01],\n","        [-3.0350e-01],\n","        [-7.6218e-01],\n","        [ 1.6131e+00],\n","        [-1.1631e+00],\n","        [ 1.0864e+00],\n","        [-4.7766e-01],\n","        [-1.6038e-01],\n","        [-8.4064e-01],\n","        [-9.4669e-01],\n","        [-3.7420e-01],\n","        [-1.8883e-01],\n","        [-1.1640e-01]])]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ENFPjgHSCAV","outputId":"99b8f721-1ee0-40ef-e99a-2f8c83a52722"},"source":["model"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Net(\n","  (linear1): Linear(in_features=8, out_features=128, bias=True)\n","  (linear2): Linear(in_features=128, out_features=64, bias=True)\n","  (linear3): Linear(in_features=64, out_features=32, bias=True)\n","  (linear4): Linear(in_features=32, out_features=1, bias=True)\n",")"]},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"tWzZl_LRTd6J"},"source":["## Train Network"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fck--1cFP1Rd","outputId":"f18e4721-7de2-4194-89bc-d360d1216084","executionInfo":{"status":"ok","timestamp":1638914366913,"user_tz":-120,"elapsed":28937,"user":{"displayName":"Pavlos Apostolatos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUcIhXd9Iu-oLhTPKlwqLJcWeuJzkMcL0JT3cW=s64","userId":"18149797479608505262"}}},"source":["for epoch in range(100):\n","  batch_losses = []\n","\n","  for x_batch, y_batch in dataloader:\n","    y_pred = model(x_batch)\n","    \n","    loss = loss_func(y_pred, y_batch)\n","    batch_losses.append(loss.item())\n","    \n","    #Delete previously stored gradients\n","    optimizer.zero_grad()\n","    #Perform backpropagation starting from the loss calculated in this epoch\n","    loss.backward()\n","    #Update model's weights based on the gradients calculated during backprop\n","    optimizer.step()\n","  \n","  print(f\"Epoch {epoch:3}: Loss = {sum(batch_losses)/len(dataloader):.5f}\")\n","    "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch   0: Loss = 23.07366\n","Epoch   1: Loss = 23.05640\n","Epoch   2: Loss = 23.04923\n","Epoch   3: Loss = 23.08227\n","Epoch   4: Loss = 23.08470\n","Epoch   5: Loss = 23.03137\n","Epoch   6: Loss = 23.04910\n","Epoch   7: Loss = 23.06604\n","Epoch   8: Loss = 23.04250\n","Epoch   9: Loss = 23.03983\n","Epoch  10: Loss = 23.04872\n","Epoch  11: Loss = 23.04682\n","Epoch  12: Loss = 23.04315\n","Epoch  13: Loss = 23.03031\n","Epoch  14: Loss = 23.04879\n","Epoch  15: Loss = 23.04778\n","Epoch  16: Loss = 23.01762\n","Epoch  17: Loss = 23.04221\n","Epoch  18: Loss = 23.05282\n","Epoch  19: Loss = 23.02865\n","Epoch  20: Loss = 23.03847\n","Epoch  21: Loss = 22.99498\n","Epoch  22: Loss = 23.04007\n","Epoch  23: Loss = 23.05867\n","Epoch  24: Loss = 22.97663\n","Epoch  25: Loss = 23.05040\n","Epoch  26: Loss = 23.05760\n","Epoch  27: Loss = 23.04377\n","Epoch  28: Loss = 23.03008\n","Epoch  29: Loss = 23.04940\n","Epoch  30: Loss = 23.02832\n","Epoch  31: Loss = 23.04114\n","Epoch  32: Loss = 23.06131\n","Epoch  33: Loss = 23.02411\n","Epoch  34: Loss = 23.04587\n","Epoch  35: Loss = 23.04067\n","Epoch  36: Loss = 23.04783\n","Epoch  37: Loss = 23.03584\n","Epoch  38: Loss = 23.02618\n","Epoch  39: Loss = 23.04641\n","Epoch  40: Loss = 23.05695\n","Epoch  41: Loss = 23.02509\n","Epoch  42: Loss = 23.05577\n","Epoch  43: Loss = 23.03292\n","Epoch  44: Loss = 23.07652\n","Epoch  45: Loss = 23.06447\n","Epoch  46: Loss = 23.04287\n","Epoch  47: Loss = 23.04467\n","Epoch  48: Loss = 23.04143\n","Epoch  49: Loss = 23.03574\n","Epoch  50: Loss = 23.06545\n","Epoch  51: Loss = 23.05118\n","Epoch  52: Loss = 23.05752\n","Epoch  53: Loss = 23.05687\n","Epoch  54: Loss = 23.04302\n","Epoch  55: Loss = 23.05002\n","Epoch  56: Loss = 23.02623\n","Epoch  57: Loss = 23.01376\n","Epoch  58: Loss = 23.01155\n","Epoch  59: Loss = 23.03209\n","Epoch  60: Loss = 23.00481\n","Epoch  61: Loss = 23.03204\n","Epoch  62: Loss = 23.05443\n","Epoch  63: Loss = 23.03349\n","Epoch  64: Loss = 23.03765\n","Epoch  65: Loss = 23.03104\n","Epoch  66: Loss = 23.05135\n","Epoch  67: Loss = 23.05809\n","Epoch  68: Loss = 23.04218\n","Epoch  69: Loss = 23.05755\n","Epoch  70: Loss = 23.03907\n","Epoch  71: Loss = 23.03592\n","Epoch  72: Loss = 23.02058\n","Epoch  73: Loss = 23.01559\n","Epoch  74: Loss = 23.05133\n","Epoch  75: Loss = 22.99088\n","Epoch  76: Loss = 23.03309\n","Epoch  77: Loss = 23.01632\n","Epoch  78: Loss = 23.05014\n","Epoch  79: Loss = 23.05285\n","Epoch  80: Loss = 23.04893\n","Epoch  81: Loss = 23.03661\n","Epoch  82: Loss = 23.02193\n","Epoch  83: Loss = 23.04357\n","Epoch  84: Loss = 23.02448\n","Epoch  85: Loss = 23.03247\n","Epoch  86: Loss = 23.02515\n","Epoch  87: Loss = 23.02112\n","Epoch  88: Loss = 23.00202\n","Epoch  89: Loss = 23.02123\n","Epoch  90: Loss = 23.04310\n","Epoch  91: Loss = 23.06025\n","Epoch  92: Loss = 23.05342\n","Epoch  93: Loss = 23.02342\n","Epoch  94: Loss = 23.01640\n","Epoch  95: Loss = 23.03525\n","Epoch  96: Loss = 23.02914\n","Epoch  97: Loss = 23.05079\n","Epoch  98: Loss = 22.99627\n","Epoch  99: Loss = 23.04402\n"]}]}]}